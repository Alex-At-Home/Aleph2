/*******************************************************************************
 * Copyright 2015, The IKANOW Open Source Project.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 *   http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 ******************************************************************************/
package com.ikanow.aleph2.data_model.interfaces.data_import;

import java.util.Optional;
import java.util.concurrent.Future;

import org.checkerframework.checker.nullness.qual.NonNull;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.node.ObjectNode;
import com.ikanow.aleph2.data_model.interfaces.shared_services.ICrudService;
import com.ikanow.aleph2.data_model.objects.data_import.AnnotationBean;
import com.ikanow.aleph2.data_model.objects.data_import.DataBucketBean;
import com.ikanow.aleph2.data_model.objects.data_import.DataBucketStatusBean;
import com.ikanow.aleph2.data_model.objects.shared.BasicMessageBean;

public interface IEnrichmentModuleContext {

	////////////////////////////////////////////
	
	// Batch/streaming topology
	
	/** (Topology only) This string should be passed into ContextUtils.getEnrichmentContext to retrieve this class from within external clients
	 * @param bucket An optional bucket - if there is no ambiguity in the bucket then Optional.empty() can be passed (Note that the behavior of the context if called on another bucket than the one currently being processed is undefined) 
	 * @return an opaque string that can be passed into ContextUtils.getEnrichmentContext
	 */
	@NonNull 
	String getEnrichmentContextSignature(@NonNull Optional<DataBucketBean> bucket);
	
	////////////////////////////////////////////
	
	// Batch topology context

	//TODO (ALEPH-4): not yet supported
	
	////////////////////////////////////////////
	
	// Streaming topology context
	
	/** For use in the topology generated by IEnrichmentStreamingTopology.getTopologyAndConfiguration - this stage outputs objects from the harvest stage
	 * @param clazz - the requested class of the topology entry point (eg BaseRichSpout for Storm) 
	 * @param bucket - the bucket associated with this topology (if clear from the context this can be set to Optional.empty)
	 * @return an instance of the requested class
	 */
	@NonNull 
	<T> T getTopologyEntryPoint(@NonNull Class<T> clazz, @NonNull Optional<DataBucketBean> bucket);	
	
	/** For use in the topology generated by IEnrichmentStreamingTopology.getTopologyAndConfiguration - this stage stores objects coming out of the enrichment stage
	 * @param clazz - the requested class of the topology success end point (eg BaseRichBolt for Storm) - ie objects to be stored in the platform 
	 * @param bucket - the bucket associated with this topology (if clear from the context this can be set to Optional.empty)
	 * @return an instance of the requested class
	 */
	@NonNull 
	<T> T getTopologyStorageEndpoint(@NonNull Class<T> clazz, @NonNull Optional<DataBucketBean> bucket);
	
	/** For use in the topology generated by IEnrichmentStreamingTopology.getTopologyAndConfiguration - this stage temporarily stores failed objects for further inspection
	 * @param clazz - the requested class of the topology success end point (eg BaseRichBolt for Storm) - ie objects to be stored temporarily for further inspection
	 * @param bucket - the bucket associated with this topology (if clear from the context this can be set to Optional.empty)
	 * @return an instance of the requested class
	 */
	@NonNull 
	<T> T getTopologyErrorEndpoint(@NonNull Class<T> clazz, @NonNull Optional<DataBucketBean> bucket);
	
	////////////////////////////////////////////
	
	// Batch module context
	
	// The API is somewhat restrictive in order to allow multi-threaded operations efficiently
	// - you can make an immutable JsonNode mutable and then emit it
	//   BUT if you're in parallel mode, then this results in a (potentially deep) copy 
	// - or you emit the object with a set of mutations (if this is possible) and the context will take care of syncing 
	//   multiple changes (replace values, merge maps and sets, append collections; null value unsets)
	// - the latter is always how annotations work 

	/** The first stage of the nicer-looking but less efficient emit process - make the input node mutable so you can edit it
	 * @param original - a JsonNode that will spawn a mutable object
	 * @return the mutable copy or reference of the original
	 */
	@NonNull 
	ObjectNode convertToMutable(@NonNull JsonNode original);
	
	/** The second stage of the nicer-looking but less efficient emit process - emit the mutated object
	 * @param id - the id received with the object from the EnrichmentBatchModule call
	 * @param mutated_json - the mutated object to emit
	 * @param annotation - a set of annotations to include in the emitted object
	 */
	void emitMutableObject(long id, @NonNull ObjectNode mutated_json, @NonNull Optional<AnnotationBean> annotation);
	
	/** The most efficient (slightly uglier) emit process - emit the original object with a list of applied mutations
	 * @param id - the id received with the object from the IEnrichmentBatchModule onObjectBatch or onAggregatedObjectBatch call
	 * @param original_json - the json doc received
	 * @param mutations - a list of "mutations" that are applied to the original_json (replace values, merge maps and sets, append collections; null value unsets)
	 * @param annotation - a set of annotations to include in the emitted object
	 */
	void emitImmutableObject(long id, @NonNull JsonNode original_json, @NonNull Optional<ObjectNode> mutations, @NonNull Optional<AnnotationBean> annotations);
	
	/** Enables the batch process to store an object that failed for future analysis
	 * @param id the id of the object received from the IEnrichmentBatchModule onObjectBatch or onAggregatedObjectBatch call
	 * @param original_json
	 */
	void storeErroredObject(long id, @NonNull JsonNode original_json);
	
	/** Returns the next unused id, enabling new objects to be added to the enrichment processing
	 * @return the next id that safely creates a new object
	 */
	long getNextUnusedId();
	
	////////////////////////////////////////////
	
	// Streaming module context
	
	//TODO (ALEPH-4): not yet supported
	
	////////////////////////////////////////////
	
	// Common:
	
	/** (All Enrichment Types) Returns a service - for external clients, the corresponding library JAR must have been copied into the class file (path given by getHarvestContextLibraries)
	 * @param service_clazz - the class of the object desired; if specified, this overrides to a secondary service
	 * @param service_name - optional - if ommitted, this is the default service of this type
	 * @return the requested service (optionally)
	 */
	@NonNull 
	<I> Optional<I> getService(@NonNull Class<I> service_clazz, @NonNull Optional<String> service_name);
	
	/** (All Enrichment Types) Returns an object repository that the harvester/module can use to store arbitrary internal state
	 * @param bucket An optional bucket - if there is no ambiguity in the bucket then Optional.empty() can be passed (Note that the behavior of the context if called on another bucket than the one currently being processed is undefined) 
	 * @param sub_collection - arbitrary string, enables the user to split the per library state into multiple independent collections. If left empty then defaults to "encirhment". It is recommended to prefix with "enrichment_" (or leave auto_apply_prefix true) to avoid collisions with harvest/analytic modules.
	 * @param auto_apply_prefix - if true then auto applies the prefix "enrichment_" to the supplied sub-collection 
	 * @return a generic object repository
	 */
	@NonNull 
	<S> ICrudService<S> getBucketObjectStore(@NonNull Class<S> clazz, @NonNull Optional<DataBucketBean> bucket, @NonNull Optional<String> sub_collection, boolean auto_apply_prefix);
	
	/** (All Enrichment Types) Returns the status bean for the specified bucket
	 * @param bucket An optional bucket - if there is no ambiguity in the bucket then Optional.empty() can be passed (Note that the behavior of the context if called on another bucket than the one currently being processed is undefined) 
	 * @return A Future containing a bean containing the harvests state and status
	 */
	@NonNull 
	Future<DataBucketStatusBean> getBucketStatus(@NonNull Optional<DataBucketBean> bucket);
	
	/** (All Enrichment Types) Calling this function logs a status message into he DataBucketStatusBean that is visible to the user
	 * Note that the behavior of the context if called on another bucket than the one
	 * currently being processed is undefined
	 * @param bucket An optional bucket - if there is no ambiguity in the bucket then Optional.empty() can be passed (Note that the behavior of the context if called on another bucket than the one currently being processed is undefined) 
	 * @param The message to log
	 * @param roll_up_duplicates if set (default: true) then identical messages are not logged separately 
	 */
	void logStatusForBucketOwner(@NonNull Optional<DataBucketBean> bucket, @NonNull BasicMessageBean message, boolean roll_up_duplicates);
	
	/** (All Enrichment Types) Calling this function logs a status message into he DataBucketStatusBean that is visible to the user
	 * @param bucket An optional bucket - if there is no ambiguity in the bucket then Optional.empty() can be passed (Note that the behavior of the context if called on another bucket than the one currently being processed is undefined) 
	 * @param The message to log (duplicates are "rolled up")
	 */
	void logStatusForBucketOwner(@NonNull Optional<DataBucketBean> bucket, @NonNull BasicMessageBean message);
	
	/** (All Enrichment Types) Requests that the bucket be suspended - in addition to changing the bucket state, this will result in a call to IHarvestTechnologyModule.onSuspend
	 * @param bucket An optional bucket - if there is no ambiguity in the bucket then Optional.empty() can be passed (Note that the behavior of the context if called on another bucket than the one currently being processed is undefined) 
	 */
	void emergencyDisableBucket(@NonNull Optional<DataBucketBean> bucket);
	
	/** (All Enrichment Types) Requests that the bucket be suspended for the specified duration - in addition to changing the bucket state, this will result in a call to IHarvestTechnologyModule.onSuspend
	 * @param bucket An optional bucket - if there is no ambiguity in the bucket then Optional.empty() can be passed (Note that the behavior of the context if called on another bucket than the one currently being processed is undefined)
	 * @param  quarantineDuration A string representing the duration for which to quarantine the data (eg "1 hour", "2 days", "3600")
	 */
	void emergencyQuarantineBucket(@NonNull Optional<DataBucketBean> bucket, @NonNull String quarantine_duration);

	////////////////////////////////////////////
	
	/** (Should never be called by clients) this is used by the infrastructure to set up external contexts
	 * @param signature the string returned from getEnrichmentContextSignature
	 */
	void initializeNewContext(@NonNull String signature);	

	////////////////////////////////////////////
	
	/** USE WITH CARE: this returns the driver to the underlying technology
	 *  shouldn't be used unless absolutely necessary!
	 * @param driver_class the class of the driver
	 * @param a string containing options in some technology-specific format
	 * @return a driver to the underlying technology. Will exception if you pick the wrong one!
	 */
	@NonNull 
	<T> T getUnderlyingPlatformDriver(@NonNull Class<T> driver_class, @NonNull Optional<String> driver_options);
}
